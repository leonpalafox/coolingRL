{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Environment(object):\n",
        "    \"\"\"\n",
        "    Server Temperature Control Environment\n",
        "\n",
        "    This environment simulates a server cooling system where:\n",
        "    - AI can take actions to cool down or heat up the server\n",
        "    - The goal is to maintain optimal temperature while minimizing energy consumption\n",
        "    - External factors like atmospheric temperature, number of users, and data rate affect the server temperature\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, optimal_temperature=[18.0, 24.0], initial_month=0,\n",
        "                 initial_number_users=10, initial_rate_data=60):\n",
        "        \"\"\"\n",
        "        Initialize the environment\n",
        "\n",
        "        Parameters:\n",
        "        - optimal_temperature: [min_optimal, max_optimal] temperature range in Celsius\n",
        "        - initial_month: starting month (0-11, where 0=January)\n",
        "        - initial_number_users: initial number of users on the server\n",
        "        - initial_rate_data: initial data processing rate\n",
        "        \"\"\"\n",
        "\n",
        "        # === TEMPORAL PARAMETERS ===\n",
        "        self.initial_month = initial_month\n",
        "\n",
        "        # Monthly atmospheric temperatures (January to December)\n",
        "        self.monthly_atmospheric_temperatures = [1.0, 5.0, 7.0, 10.0, 11.0, 20.0,\n",
        "                                                23.0, 24.0, 22.0, 10.0, 5.0, 1.0]\n",
        "        self.atmospheric_temperature = self.monthly_atmospheric_temperatures[initial_month]\n",
        "\n",
        "        # === TEMPERATURE PARAMETERS ===\n",
        "        self.optimal_temperature = optimal_temperature  # Target temperature range\n",
        "        self.min_temperature = -20  # Absolute minimum (causes game over if reached)\n",
        "        self.max_temperature = 80   # Absolute maximum (causes game over if reached)\n",
        "\n",
        "        # === USER PARAMETERS ===\n",
        "        self.min_number_users = 10\n",
        "        self.max_number_users = 100\n",
        "        self.max_update_users = 5   # Maximum change in users per step\n",
        "        self.initial_number_users = initial_number_users\n",
        "        self.current_number_users = initial_number_users\n",
        "\n",
        "        # === DATA RATE PARAMETERS ===\n",
        "        self.min_rate_data = 20\n",
        "        self.max_rate_data = 300\n",
        "        self.max_update_data = 10   # Maximum change in data rate per step\n",
        "        self.initial_rate_data = initial_rate_data\n",
        "        self.current_rate_data = initial_rate_data\n",
        "\n",
        "        # === TEMPERATURE CALCULATIONS ===\n",
        "        # Intrinsic temperature = atmospheric + heat from users + heat from data processing\n",
        "        self.intrinsic_temperature = (self.atmospheric_temperature +\n",
        "                                    1.25 * self.current_number_users +\n",
        "                                    1.25 * self.current_rate_data)\n",
        "\n",
        "        # Server temperature with AI control\n",
        "        self.temperature_ai = self.intrinsic_temperature\n",
        "\n",
        "        # Server temperature without AI (baseline - starts at middle of optimal range)\n",
        "        self.temperature_noai = (self.optimal_temperature[0] + self.optimal_temperature[1]) / 2.0\n",
        "\n",
        "        # === ENERGY TRACKING ===\n",
        "        self.total_energy_ai = 0.0      # Total energy consumed by AI system\n",
        "        self.total_energy_noai = 0.0    # Total energy consumed by non-AI system\n",
        "\n",
        "        # === GAME STATE ===\n",
        "        self.reward = 0.0\n",
        "        self.game_over = 0\n",
        "        self.train = 1  # 1 for training mode, 0 for inference mode\n",
        "\n",
        "    def update_env(self, direction, energy_ai, month):\n",
        "        \"\"\"\n",
        "        Update the environment after AI takes an action\n",
        "\n",
        "        Parameters:\n",
        "        - direction: +1 (heating) or -1 (cooling)\n",
        "        - energy_ai: amount of energy the AI uses for the action\n",
        "        - month: current month (0-11)\n",
        "\n",
        "        Returns:\n",
        "        - next_state: normalized state vector for neural network\n",
        "        - reward: reward for the action taken\n",
        "        - game_over: whether the episode should end\n",
        "        \"\"\"\n",
        "\n",
        "        # === STEP 1: CALCULATE REWARD ===\n",
        "        # First, simulate what a non-AI system would do\n",
        "        energy_noai = 0\n",
        "        if self.temperature_noai < self.optimal_temperature[0]:\n",
        "            # Too cold - need to heat up\n",
        "            energy_noai = self.optimal_temperature[0] - self.temperature_noai\n",
        "            self.temperature_noai = self.optimal_temperature[0]\n",
        "        elif self.temperature_noai > self.optimal_temperature[1]:\n",
        "            # Too hot - need to cool down\n",
        "            energy_noai = self.temperature_noai - self.optimal_temperature[1]\n",
        "            self.temperature_noai = self.optimal_temperature[1]\n",
        "\n",
        "        # Reward = energy saved compared to non-AI system\n",
        "        self.reward = energy_noai - energy_ai\n",
        "        self.reward = 1e-3 * self.reward  # Scale reward\n",
        "\n",
        "        # === STEP 2: UPDATE ENVIRONMENTAL FACTORS ===\n",
        "        # Update atmospheric temperature based on month\n",
        "        self.atmospheric_temperature = self.monthly_atmospheric_temperatures[month]\n",
        "\n",
        "        # Randomly update number of users (simulates varying server load)\n",
        "        self.current_number_users += np.random.randint(-self.max_update_users, self.max_update_users)\n",
        "        self.current_number_users = np.clip(self.current_number_users,\n",
        "                                          self.min_number_users, self.max_number_users)\n",
        "\n",
        "        # Randomly update data processing rate\n",
        "        self.current_rate_data += np.random.randint(-self.max_update_data, self.max_update_data)\n",
        "        self.current_rate_data = np.clip(self.current_rate_data,\n",
        "                                       self.min_rate_data, self.max_rate_data)\n",
        "\n",
        "        # === STEP 3: UPDATE TEMPERATURES ===\n",
        "        # Calculate change in intrinsic temperature\n",
        "        past_intrinsic_temperature = self.intrinsic_temperature\n",
        "        self.intrinsic_temperature = (self.atmospheric_temperature +\n",
        "                                    1.25 * self.current_number_users +\n",
        "                                    1.25 * self.current_rate_data)\n",
        "        delta_intrinsic_temperature = self.intrinsic_temperature - past_intrinsic_temperature\n",
        "\n",
        "        # Calculate temperature change from AI action\n",
        "        if direction == -1:\n",
        "            delta_temperature_ai = -energy_ai  # Cooling\n",
        "        elif direction == 1:\n",
        "            delta_temperature_ai = energy_ai   # Heating\n",
        "\n",
        "        # Update AI-controlled temperature\n",
        "        self.temperature_ai += delta_intrinsic_temperature + delta_temperature_ai\n",
        "\n",
        "        # Update non-AI temperature (only affected by environmental changes)\n",
        "        self.temperature_noai += delta_intrinsic_temperature\n",
        "\n",
        "        # === STEP 4: CHECK GAME OVER CONDITIONS ===\n",
        "        if self.temperature_ai < self.min_temperature:\n",
        "            if self.train == 1:\n",
        "                self.game_over = 1  # End episode during training\n",
        "            else:\n",
        "                # During inference, apply corrective energy cost\n",
        "                self.total_energy_ai += self.optimal_temperature[0] - self.temperature_ai\n",
        "                self.temperature_ai = self.optimal_temperature[0]\n",
        "        elif self.temperature_ai > self.max_temperature:\n",
        "            if self.train == 1:\n",
        "                self.game_over = 1  # End episode during training\n",
        "            else:\n",
        "                # During inference, apply corrective energy cost\n",
        "                self.total_energy_ai += self.temperature_ai - self.optimal_temperature[1]\n",
        "                self.temperature_ai = self.optimal_temperature[1]\n",
        "\n",
        "        # === STEP 5: UPDATE ENERGY TOTALS ===\n",
        "        self.total_energy_ai += energy_ai\n",
        "        self.total_energy_noai += energy_noai\n",
        "\n",
        "        # === STEP 6: CREATE NORMALIZED STATE VECTOR ===\n",
        "        # Normalize all values to [0, 1] range for neural network input\n",
        "        scaled_temperature_ai = ((self.temperature_ai - self.min_temperature) /\n",
        "                               (self.max_temperature - self.min_temperature))\n",
        "        scaled_number_users = ((self.current_number_users - self.min_number_users) /\n",
        "                             (self.max_number_users - self.min_number_users))\n",
        "        scaled_rate_data = ((self.current_rate_data - self.min_rate_data) /\n",
        "                          (self.max_rate_data - self.min_rate_data))\n",
        "\n",
        "        next_state = np.matrix([scaled_temperature_ai, scaled_number_users, scaled_rate_data])\n",
        "\n",
        "        return next_state, self.reward, self.game_over\n",
        "\n",
        "    def reset(self, new_month):\n",
        "        \"\"\"\n",
        "        Reset the environment to initial state for a new episode\n",
        "\n",
        "        Parameters:\n",
        "        - new_month: starting month for the new episode (0-11)\n",
        "        \"\"\"\n",
        "        self.atmospheric_temperature = self.monthly_atmospheric_temperatures[new_month]\n",
        "        self.initial_month = new_month\n",
        "        self.current_number_users = self.initial_number_users\n",
        "        self.current_rate_data = self.initial_rate_data\n",
        "\n",
        "        # Recalculate intrinsic temperature\n",
        "        self.intrinsic_temperature = (self.atmospheric_temperature +\n",
        "                                    1.25 * self.current_number_users +\n",
        "                                    1.25 * self.current_rate_data)\n",
        "\n",
        "        # Reset temperatures\n",
        "        self.temperature_ai = self.intrinsic_temperature\n",
        "        self.temperature_noai = (self.optimal_temperature[0] + self.optimal_temperature[1]) / 2.0\n",
        "\n",
        "        # Reset tracking variables\n",
        "        self.total_energy_ai = 0.0\n",
        "        self.total_energy_noai = 0.0\n",
        "        self.reward = 0.0\n",
        "        self.game_over = 0\n",
        "        self.train = 1\n",
        "\n",
        "    def observe(self):\n",
        "        \"\"\"\n",
        "        Get the current state of the environment\n",
        "\n",
        "        Returns:\n",
        "        - current_state: normalized state vector [temperature, users, data_rate]\n",
        "        - reward: last reward received\n",
        "        - game_over: whether the episode has ended\n",
        "        \"\"\"\n",
        "        # Normalize current state\n",
        "        scaled_temperature_ai = ((self.temperature_ai - self.min_temperature) /\n",
        "                               (self.max_temperature - self.min_temperature))\n",
        "        scaled_number_users = ((self.current_number_users - self.min_number_users) /\n",
        "                             (self.max_number_users - self.min_number_users))\n",
        "        scaled_rate_data = ((self.current_rate_data - self.min_rate_data) /\n",
        "                          (self.max_rate_data - self.min_rate_data))\n",
        "\n",
        "        current_state = np.matrix([scaled_temperature_ai, scaled_number_users, scaled_rate_data])\n",
        "\n",
        "        return current_state, self.reward, self.game_over\n"
      ],
      "metadata": {
        "id": "wPZCRCDh2QHi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=== SERVER COOLING ENVIRONMENT DEMONSTRATION ===\\n\")\n",
        "\n",
        "    # Create environment starting in January (month 0)\n",
        "    env = Environment(optimal_temperature=[18.0, 24.0], initial_month=0,\n",
        "                     initial_number_users=20, initial_rate_data=80)\n",
        "\n",
        "    print(\"1. INITIAL STATE:\")\n",
        "    print(f\"   Atmospheric temperature: {env.atmospheric_temperature}°C\")\n",
        "    print(f\"   Number of users: {env.current_number_users}\")\n",
        "    print(f\"   Data rate: {env.current_rate_data}\")\n",
        "    print(f\"   Intrinsic temperature: {env.intrinsic_temperature:.2f}°C\")\n",
        "    print(f\"   AI temperature: {env.temperature_ai:.2f}°C\")\n",
        "    print(f\"   No-AI temperature: {env.temperature_noai:.2f}°C\")\n",
        "    print(f\"   Optimal range: {env.optimal_temperature[0]}-{env.optimal_temperature[1]}°C\")\n",
        "\n",
        "    # Get initial observation\n",
        "    state, reward, game_over = env.observe()\n",
        "    print(f\"\\n2. INITIAL OBSERVATION:\")\n",
        "    print(f\"   Normalized state: {state}\")\n",
        "    print(f\"   Reward: {reward}\")\n",
        "    print(f\"   Game over: {game_over}\")\n",
        "\n",
        "    print(f\"\\n3. TAKING ACTIONS:\")\n",
        "\n",
        "    # Example 1: AI tries to cool down the server\n",
        "    print(f\"\\n   ACTION 1: Cool down (direction=-1, energy=2.0)\")\n",
        "    print(f\"   Before action - AI temp: {env.temperature_ai:.2f}°C\")\n",
        "\n",
        "    next_state, reward, game_over = env.update_env(direction=-1, energy_ai=2.0, month=0)\n",
        "\n",
        "    print(f\"   After action - AI temp: {env.temperature_ai:.2f}°C\")\n",
        "    print(f\"   Reward: {reward:.6f}\")\n",
        "    print(f\"   New state: {next_state}\")\n",
        "    print(f\"   Game over: {game_over}\")\n",
        "\n",
        "    # Example 2: AI tries to heat up the server\n",
        "    print(f\"\\n   ACTION 2: Heat up (direction=+1, energy=1.5)\")\n",
        "    print(f\"   Before action - AI temp: {env.temperature_ai:.2f}°C\")\n",
        "\n",
        "    next_state, reward, game_over = env.update_env(direction=1, energy_ai=1.5, month=1)\n",
        "\n",
        "    print(f\"   After action - AI temp: {env.temperature_ai:.2f}°C\")\n",
        "    print(f\"   Reward: {reward:.6f}\")\n",
        "    print(f\"   New state: {next_state}\")\n",
        "    print(f\"   Game over: {game_over}\")\n",
        "\n",
        "    # Show how environmental factors changed\n",
        "    print(f\"\\n4. ENVIRONMENTAL CHANGES:\")\n",
        "    print(f\"   Atmospheric temp: {env.atmospheric_temperature}°C (changed to February)\")\n",
        "    print(f\"   Number of users: {env.current_number_users} (randomly updated)\")\n",
        "    print(f\"   Data rate: {env.current_rate_data} (randomly updated)\")\n",
        "    print(f\"   Total energy - AI: {env.total_energy_ai:.2f}\")\n",
        "    print(f\"   Total energy - No AI: {env.total_energy_noai:.2f}\")\n",
        "\n",
        "    # Reset environment\n",
        "    print(f\"\\n5. RESETTING ENVIRONMENT:\")\n",
        "    env.reset(new_month=6)  # Reset to July\n",
        "    state, reward, game_over = env.observe()\n",
        "    print(f\"   Reset to July - Atmospheric temp: {env.atmospheric_temperature}°C\")\n",
        "    print(f\"   AI temperature: {env.temperature_ai:.2f}°C\")\n",
        "    print(f\"   Reset state: {state}\")\n",
        "\n",
        "    print(f\"\\n=== END OF DEMONSTRATION ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuBNEdcv2UEM",
        "outputId": "98f43460-54e7-42ea-c97c-a7610c16a93e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== SERVER COOLING ENVIRONMENT DEMONSTRATION ===\n",
            "\n",
            "1. INITIAL STATE:\n",
            "   Atmospheric temperature: 1.0°C\n",
            "   Number of users: 20\n",
            "   Data rate: 80\n",
            "   Intrinsic temperature: 126.00°C\n",
            "   AI temperature: 126.00°C\n",
            "   No-AI temperature: 21.00°C\n",
            "   Optimal range: 18.0-24.0°C\n",
            "\n",
            "2. INITIAL OBSERVATION:\n",
            "   Normalized state: [[1.46       0.11111111 0.21428571]]\n",
            "   Reward: 0.0\n",
            "   Game over: 0\n",
            "\n",
            "3. TAKING ACTIONS:\n",
            "\n",
            "   ACTION 1: Cool down (direction=-1, energy=2.0)\n",
            "   Before action - AI temp: 126.00°C\n",
            "   After action - AI temp: 124.00°C\n",
            "   Reward: -0.002000\n",
            "   New state: [[1.44       0.12222222 0.21071429]]\n",
            "   Game over: 1\n",
            "\n",
            "   ACTION 2: Heat up (direction=+1, energy=1.5)\n",
            "   Before action - AI temp: 124.00°C\n",
            "   After action - AI temp: 123.25°C\n",
            "   Reward: -0.001500\n",
            "   New state: [[1.4325     0.16666667 0.17857143]]\n",
            "   Game over: 1\n",
            "\n",
            "4. ENVIRONMENTAL CHANGES:\n",
            "   Atmospheric temp: 5.0°C (changed to February)\n",
            "   Number of users: 25 (randomly updated)\n",
            "   Data rate: 70 (randomly updated)\n",
            "   Total energy - AI: 3.50\n",
            "   Total energy - No AI: 0.00\n",
            "\n",
            "5. RESETTING ENVIRONMENT:\n",
            "   Reset to July - Atmospheric temp: 23.0°C\n",
            "   AI temperature: 148.00°C\n",
            "   Reset state: [[1.68       0.11111111 0.21428571]]\n",
            "\n",
            "=== END OF DEMONSTRATION ===\n"
          ]
        }
      ]
    }
  ]
}